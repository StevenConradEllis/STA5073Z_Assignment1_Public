[
  {
    "objectID": "template.html",
    "href": "template.html",
    "title": "A demonstration of the achemso class1",
    "section": "",
    "text": "Some journals require a graphical entry for the Table of Contents. This should be laid out ``print ready’’ so that the sizing of the text is correct.\nInside the tocentry environment, the font used is Helvetica 8,pt, as required by Journal of the American Chemical Society.\nThe surrounding frame is 9cm by 3.5cm, which is the maximum permitted for Journal of the American Chemical Society graphical table of content entries. The box will not resize if the content is too big: instead it will overflow the edge of the box.\nThis box and the associated title will always be printed on a separate page at the end of the document."
  },
  {
    "objectID": "template.html#introduction",
    "href": "template.html#introduction",
    "title": "A demonstration of the achemso class1",
    "section": "Introduction",
    "text": "Introduction\nThis is a paragraph of text to fill the introduction of the demonstration file. The demonstration file attempts to show the modifications of the standard LaTeX macros that are implemented by the achemso class. These are mainly concerned with content, as opposed to appearance."
  },
  {
    "objectID": "template.html#results-and-discussion",
    "href": "template.html#results-and-discussion",
    "title": "A demonstration of the achemso class1",
    "section": "Results and discussion",
    "text": "Results and discussion\n\nOutline\nThe document layout should follow the style of the journal concerned. Where appropriate, sections and subsections should be added in the normal way. If the class options are set correctly, warnings will be given if these should not be present.\n\n\nReferences\nThe class makes various changes to the way that references are handled. The class loads natbib, and also the appropriate bibliography style. References can be made using the normal method; the citation should be placed before any punctuation, as the class will move it if using a superscript citation style (Garnier2007?). The use of natbib allows the use of the various citation commands of that package have shown something. Long lists of authors will be automatically truncated in most article formats, but not in supplementary information or reviews. If you encounter problems with the citation macros, please check that your copy of natbib is up to date. The demonstration database file bibliography.bib shows how to complete entries correctly.\nMultiple citations to be combined into a list can be given as a single citation. This uses the mciteplus package. Citations other than the first of the list should be indicated with a star.\nThe class also handles notes to be added to the bibliography. These should be given in place in the document. As with citations, the text should be placed before punctuation. A note is also generated if a citation has an optional note. This assumes that the whole work has already been cited: odd numbering will result if this is not the case .\n\n\nFloats\nNew float types are automatically set up by the class file. The means graphics are included as follows (Figure 1). As illustrated, the float is here if possible.\n\nYour scheme graphic would go here: .eps format for , or .pdf (or .png) for pdf\\ files are best saved as .eps files: these can be scaled without loss of quality, and can be converted to .pdf files easily using eps2pdf.\n\n\n\n\nFigure 1: An example scheme\n\n\n\n\nAs well as the standard float types table and figure, the class also recognises scheme, chart and graph.\nFigure 2: A second example figure\n\n\nCharts, figures and schemes do not necessarily have to be labelled or captioned. However, tables should always have a title. It is possible to include a number and label for a graphic without any title, using an empty argument to the \\caption macro.\nThe use of the different floating environments is not required, but it is intended to make document preparation easier for authors. In general, you should place your graphics where they make logical sense; the production process will move them if needed.\n\n\nMath(s)\nThe achemso class does not load any particular additional support for mathematics. If packages such as amsmath are required, they should be loaded in the preamble. However, the basic LaTeX math(s) input should work correctly without this. Some inline material \\(y = mx + c\\) or \\(1 + 1 = 2\\) followed by some display.\n\\[ A = \\pi r^2 \\]\nIt is possible to label equations in the usual way (Equation 1).\n\\[\n  \\frac{\\mathrm{d}}{\\mathrm{d}x} \\, r^2 = 2r\n\\tag{1}\\]\nThis can also be used to have equations containing graphical content. To align the equation number with the middle of the graphic, rather than the bottom, a minipage may be used."
  },
  {
    "objectID": "template.html#experimental",
    "href": "template.html#experimental",
    "title": "A demonstration of the achemso class1",
    "section": "Experimental",
    "text": "Experimental\nThe usual experimental details should appear here. This could include a table, which can be referenced as Table 1. Notice that the caption is positioned at the top of the table.\n\n\nTable 1: An example table\n\n\nHeader one\nHeader two\n\n\n\n\nEntry one\nEntry two\n\n\nEntry three\nEntry four\n\n\nEntry five\nEntry six\n\n\nEntry seven\nEntry eight\n\n\n\n\nYou may add footnotes to ables as illustrated (Table 2).\n\n\nTable 2: An example table with notes\n\n\nHeader one\nHeader two\n\n\n\n\nEntry one2\nEntry two\n\n\nEntry three3\nEntry four\n\n\nEntry five\nEntry six\n\n\nEntry seven\nEntry eight\n\n\n\n\nThe example file also loads the optional mhchem package, so that formulas are easy to input: [H2SO4]{.ce} gives H2SO4. See the use in the bibliography file (when using titles in the references section).\nThe use of new commands should be limited to simple things which will not interfere with the production process. For example, \\textbackslash mycommand has been defined in this example, to give italic, mono-spaced text: ."
  },
  {
    "objectID": "template.html#extra-information-when-writing-jacs-communications",
    "href": "template.html#extra-information-when-writing-jacs-communications",
    "title": "A demonstration of the achemso class1",
    "section": "Extra information when writing JACS Communications",
    "text": "Extra information when writing JACS Communications\nWhen producing communications for J.~Am. Chem. Soc., the class will automatically lay the text out in the style of the journal. This gives a guide to the length of text that can be accommodated in such a publication. There are some points to bear in mind when preparing a JACS Communication in this way. The layout produced here is a model for the published result, and the outcome should be taken as a guide to the final length. The spacing and sizing of graphical content is an area where there is some flexibility in the process. You should not worry about the space before and after graphics, which is set to give a guide to the published size. This is very dependant on the final published layout.\nYou should be able to use the same source to produce a JACS Communication and a normal article. For example, this demonstration file will work with both type=article and type=communication. Sections and any abstract are automatically ignored, although you will get warnings to this effect.\n\nPlease use “The authors thank ” rather than “The authors would like to thank ”.\nThe author thanks Mats Dahlgren for version one of achemso, and Donald Arseneau for the code taken from cite to move citations after punctuation. Many users have provided feedback on the class, which is reflected in all of the different demonstrations shown in this document.\n\n\nThis will usually read something like: “Experimental procedures and characterization data for all new compounds. The class will automatically add a sentence pointing to the information on-line:"
  },
  {
    "objectID": "template.html#references-1",
    "href": "template.html#references-1",
    "title": "A demonstration of the achemso class1",
    "section": "References",
    "text": "References"
  },
  {
    "objectID": "template.html#footnotes",
    "href": "template.html#footnotes",
    "title": "A demonstration of the achemso class1",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA footnote for the title↩︎\nThis is a footnote↩︎\nThis is a second note↩︎\nA footnote for the title↩︎\nA footnote for the title↩︎\nA footnote for the title↩︎"
  },
  {
    "objectID": "assignment1.html",
    "href": "assignment1.html",
    "title": "Predictive Modelling of Presidential SONA Addresses in South Africa from 1994 to 2023",
    "section": "",
    "text": "The State of the Nation Address of the President of South Africa is an annual event in the Republic of South Africa, in which the President of South Africa reports on the status of the nation, normally to the resumption of a joint sitting of Parliament.\nThis assignment generated four predictive models that attempt to predict from a sentence the South African president who delivered it. The data-set provided included 36 speeches from 1994 to 2023 delivered by six different presidents.\nA review of academic articles revealed that the use of neural networks for topic modelling and text analysis has been identified as a fast-growing research area. (Zhao et al. 2021) (Shen et al. 2021).\nSimilarly, the use of convolutional neural networks for text classification has shown that basic CNN models can achieve very good levels of text classification performance when compared to other models such as Support Vector Machines (Baker, Korhonen, and Pyysalo 2017) (Lai et al. 2015)\nRandom forests (described later) have also demonstrated effective text classification capabilities, in some cases outperforming traditional deep-learning machine learning techniques traditionally used in this domain. (Chen et al. 2022) (Salles et al. 2018)\nFor this assignment, the speech data was imported, cleaned and transformed into word-based tokens. Since not all presidents had the same amount of speech content in the final data-set, the data-set was then balanced using various techniques, described in detail in the next section.\nFour models - a feed-forward neural network, a classification tree, a random forest and a convolutional neural network - were then run against the data-sets and thereafter individually assessed."
  },
  {
    "objectID": "assignment1.html#introduction",
    "href": "assignment1.html#introduction",
    "title": "Predictive Modelling of Presidential SONA Addresses in South Africa from 1994 to 2023",
    "section": "",
    "text": "The State of the Nation Address of the President of South Africa is an annual event in the Republic of South Africa, in which the President of South Africa reports on the status of the nation, normally to the resumption of a joint sitting of Parliament.\nThis assignment generated four predictive models that attempt to predict from a sentence the South African president who delivered it. The data-set provided included 36 speeches from 1994 to 2023 delivered by six different presidents.\nA review of academic articles revealed that the use of neural networks for topic modelling and text analysis has been identified as a fast-growing research area. (Zhao et al. 2021) (Shen et al. 2021).\nSimilarly, the use of convolutional neural networks for text classification has shown that basic CNN models can achieve very good levels of text classification performance when compared to other models such as Support Vector Machines (Baker, Korhonen, and Pyysalo 2017) (Lai et al. 2015)\nRandom forests (described later) have also demonstrated effective text classification capabilities, in some cases outperforming traditional deep-learning machine learning techniques traditionally used in this domain. (Chen et al. 2022) (Salles et al. 2018)\nFor this assignment, the speech data was imported, cleaned and transformed into word-based tokens. Since not all presidents had the same amount of speech content in the final data-set, the data-set was then balanced using various techniques, described in detail in the next section.\nFour models - a feed-forward neural network, a classification tree, a random forest and a convolutional neural network - were then run against the data-sets and thereafter individually assessed."
  },
  {
    "objectID": "assignment1.html#exploratory-data-analysis",
    "href": "assignment1.html#exploratory-data-analysis",
    "title": "Predictive Modelling of Presidential SONA Addresses in South Africa from 1994 to 2023",
    "section": "2 Exploratory Data Analysis",
    "text": "2 Exploratory Data Analysis\nFrom a review of different SONA speeches, it was evident that the style and diction of SONA speeches, across years and presidents, is remarkably similar. The speeches generally follow a set format, with common words, phrases and remarks permeating throughout. As seen in Figure 1 below, certain words are very frequently used in SONA speeches.\n\n\n\n\n\nFigure 1: Top 20 words used by all presidents.\n\n\n\n\nA review of the number of speeches delivered per president revealed that the data-set was very imbalanced, as shown in Figure 2 below, with two presidents (deKlerk and Motlanthe) only delivering one speech each.\n\n\n\n\n\nFigure 2: Total Number of Speeches per President.\n\n\n\n\nThe average number of sentences per speech delivered also varied between presidents, with deKlerk’s average significantly lower than the other presidents’, as shown in Figure 3 below.\n\n\n\n\n\nFigure 3: Average Number of Sentences per President.\n\n\n\n\nIt was evident that the commonality of words across speeches and the imbalanced data would both need to be addressed before predictive modelling could be performed."
  },
  {
    "objectID": "assignment1.html#data-and-methods",
    "href": "assignment1.html#data-and-methods",
    "title": "Predictive Modelling of Presidential SONA Addresses in South Africa from 1994 to 2023",
    "section": "3 Data and Methods",
    "text": "3 Data and Methods\n\n3.1 Data import and transformation\nAs part of the process of importing, cleaning and pre-processing the data, the following tasks were performed:\n\nAll speeches were imported from their respective .txt files into a single data-frame\nThe speech year and president were added as columns to the data-frame\nAny links or non-ASCII words were removed from the sentences via the str_replace_all() function from the R stringr library\nThe data-frame was then converted to a tibble\n\n\n\n3.2 Imbalanced data\nFrom the EDA section above, it can be seen that two presidents (deKlerk and Motlanthe) only delivered one SONA speech, meaning their words and sentences were extremely under-represented in the data-set. In addition, some presidents had more average sentences per speech than others.\nSince imbalanced data can have an adverse effect on predictive modelling, it was decided that three different data-sets would be produced for predictive modelling:\n\nAn imbalanced data-set, where presidential speeches were left in their original proportions\nA under-sampled data-set: in this data-set, the speeches the two presidents with only one speech (deKlerk and Motlanthe) were removed. On the remaining data-set, under-sampling was performed by limiting each president’s sentences to the minimum number of sentences delivered by a president within the remaining consort (1665 sentences per president)\nAn over-sampled data-set. Over-sampling involves adding more samples from under-represented classes. To achieve this, the oversample_smote() function by the R scutr library was used to create synthetic samples from under-represented presidential sentences, with the end result that each president had an equal number of speeches in the final over-sampled data-set.\n\nIn order to prepare the data-set into one against which various predictive models could be run, the data-set needed to be tokenized and transformed from ‘long’ to ‘wide’ format, where each word (and the frequency count of how often it was represented in a sentence delivered by a president) was represented as a numeric column in a sparse and wide data-set.\nTo achieve this, the data-set was first tokenized into sentences, using the unnest_tokens() function from the R tidytext library, which split the speeches column into sentence tokens, flattening the resulting data-set into one-sentence-per-row.\nThereafter, two methodologies were used to word-tokenize the resulting data-set: the bag-of-words method and term frequency-inverse-document-frequency (tf-idf) method.\n\n\n3.3 Bag-of-words\nIn a bag-of-words model, a document corpus is represented by the frequency counts of the words used therein, via a simplified representation that ignores word order and grammar.\nTo achieve a bag-of-words mode against the sentence tokens, all sentences had stop-words removed, and were then tokenized per word. From the tidy word-tokenized data-set, the top 200 most widely-used words were extracted. Thereafter, the number of times each of these 200 words was used in each sentence was calculated. Finally, the resulting data-set was re-shaped using R pivot_wider() function, so that each sentence was in its own row, and each word in its own column (with each column value representing the word’s frequency count for that row’s sentence).\nThis wide, sparse and untidy data-set was then ready for predictive modelling.\nThe bag-of-words transformation was performed on all three data-sets (imbalanced, under-sampled and over-sampled).\n\n\n3.4 Term frequency-inverse-document-frequency (TF-IDF)\nWhat is clear from reading some of the SONA speeches is that certain words and phrases are habitually repeated by all presidents. In order to assist with predictive modelling, a common technique is to down-weigh words in a term that are used frequently by all presidents (such as ‘deliver’, ‘budget’, ‘economy’, ‘invest’) and up-weigh words that are more frequently used only by a single president.\nThis is what tf-idf aims to achieve. It calculates a inverse-document-frequency-weighted-term-frequencies score for each word, which is low for words commonly used in many documents, and higher for words that are not used by many documents in a corpus.\nThe tf-idf scores for each word were calculated using the bind_tf_idf() function from the R tidytext library.\nThe tf-idf transformation was also performed on all three data-sets (imbalanced, under-sampled and over-sampled).\n\n\n3.5 Test and training data-sets\nOnce Bag of Words and tf-idf transformations were completed on the three data-sets, they were split into training and testing sets. The split chosen was a 70/30 split, where 70% of the observations were used to train predictive models and 30 were used for testing.\nOn both neural network and convolutional neural network models, a 10% validation set was used during model fitting.\n\n\n3.6 Model 1: Neural Network\nNeural networks are a subset of machine learning and are at the heart of deep learning algorithms. These models are comprised of a node layers, containing an input layer, one or more hidden layers, and an output layer.\nEach node, or artificial neuron, connects to another and has an associated weight and threshold. Weights are similar to the coefficients used in regression equations.\nThe weighted inputs are summed and passed through an activation function (which simply maps the summed weighted inputs to the output of the neuron, typically using a non-linear function). If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network. Otherwise, no data is passed along to the next layer of the network.\nThis topology and methodology allows the network to combine the inputs in very complex ways, and thus to model highly non-linear data-sets.\nFor this assignment, the R keras library was used, and the keras_model_sequential() function was used to create a linear stack of layers in our deep learning model. Keras was used to assemble layers into a fully-connected multi-layer perceptron. After several rounds of hyper-parameter testing, the following specifications were chosen for the model:\n\n64 units in input layer, with ReLu activation function\ndropout layer with a rate of 0.1\n128 units in hidden layer with ReLu activation function\ndropout layer with a rate of 0.2\n6 units in output layer with softmax function\n\nThe Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training, helping to prevent over-fitting. The softmax activation function was chosen for the output layer because of the multi-class classification requirement.\nTo prepare the data-set for multi-class classification, one hot encoding was performed on the target attribute target using the to_categorical() function in R keras library.\nThe Adam optimiser was selected, and the categorical_crossentropy loss function was used (because of the multi-class classification requirement), and the chosen metric was accuracy.\nWhen fitting the model a batch_size of 128 was applied and 50 epochs were chosen. A 10% validation split was used during model fitting.\n\n\n3.7 Model 2: Classification Tree\nClassification trees are used for data classification through a process known as binary recursive partitioning. This is an iterative process of splitting the data into partitions, and then splitting it up further on each of the branches.\nClassification trees are also the fundamental components to random forests (also used in this assignment). Their advantages include good interpretability (being easy to visualise) and they do not require the data to be processed before classification modelling. Their disadvantages are that they are prone to over-fitting, and they cannot guarantee global optimisation (because they are built in a greedy manner).\nTo generate classification trees models the rpart() R function was used from the rpart library.\n\n\n3.8 Model 3: Random Forest\nWhile decision trees are common supervised learning algorithms, they can be prone to bias and over-fitting. The Random Forest model strives to overcome this weakness, by combining the output of multiple decision trees to reach a single result.\nRandom forests ensure that the decision trees are de-correlated as follows: when building decision trees in a random forest, each time a split in a tree is considered, a random sample of m predictors is chosen as split candidates from the full set of p predictors. This prevents dominant predictors giving all trees in the model correlated results.\nTo generate random forest classification models, the randomForest() R function was used. After several rounds of testing, a forest of 150 trees was selected.\n\n\n3.9 Model 4: Convolutional Neural Network\nThe Convolutional Neural Network is a regularized type of feed-forward neural network, that learns feature engineering by itself via filters optimization. It is typically used for image and media recognition. CNNs use four key processes for predictive modelling:\n\nConvolution: the CNN scans the input variables (usually in matrix format) with window-like filters to detect features in the data (for example colours or edges in images).\nFeature maps: From the features found in step 1, maps are generated. For image data, such a map might highlight edges, while another might focus on colors.\nPooling: the CNN next reduces the size of these feature maps by keeping the most important information and discarding the rest.\nFully connected layers: the network then flattens the maps and uses them for predictive modelling, detecting patterns from these flattened layers.\n\nTo generate the CNN models, the text_tokenizer() and fit_text_tokenizer() functions from keras was used to vectorize the top X words from a balanced and unbalanced data-sets. These were then padded to equal length before being fitted to a convolutional network via the keras_model_sequential() function. The exercise was repeated for top 100, 200 and 300 words.\nOne hot encoding was again performed on the target attribute target using the to_categorical() function in R keras library.\nAfter several rounds of hyper-parameter testing, the following network toplogy was selected:\n\nembedding layer to convert the data into dense vectors\ndropout layer of rate 0.1\nconvolution layer (layer_conv_1d) with ReLu activation function, containing 64 filters and a kernel size of 8\nmaxpooling1D layer of size 2\ndensely-connected NN layer of dimensionality 32, with ReLu activation function\ndensely-connected NN layer of dimensionality 7, with Softmax activation function\n\nThe Adam optimiser was used, and the categorical_crossentropy loss function was used, and the chosen metric was accuracy.\nWhen fitting the model a batch_size of 128 was applied and 50 epochs were chosen. A validation split of 10% was again used during model fitting."
  },
  {
    "objectID": "assignment1.html#results",
    "href": "assignment1.html#results",
    "title": "Predictive Modelling of Presidential SONA Addresses in South Africa from 1994 to 2023",
    "section": "4 Results",
    "text": "4 Results\n\n4.1 Classification Tree\n\n\n\n\nTable 1: Classification Tree Model Prediction Accuracies\n\n\n\n\n\n\nTokenisation model\nAccuracy\n\n\n\n\nBag of words - unbalanced\n0.314\n\n\nBag of words - under-sampled\n0.294\n\n\nBag of words - over-sampled\n0.314\n\n\nTFIDF - unbalanced\n0.317\n\n\nTFIDF - under-sampled\n0.280\n\n\nTFIDF - over-sampled\n0.308\n\n\n\n\n\n\nFrom the results in Table 1 it is clear that the classification tree model generally performed poorly against all data-sets.\n\n\n\n\nTable 2: Classification Tree Model Predictions Against Unbalanced TF-IDF Data-Set\n\n\n\ndeKlerk\nMandela\nMbeki\nMotlanthe\nRamaphosa\nZuma\n\n\n\n\ndeKlerk\n0\n0\n1\n0\n0\n23\n\n\nMandela\n0\n0\n88\n0\n0\n368\n\n\nMbeki\n0\n0\n166\n0\n2\n508\n\n\nMotlanthe\n0\n0\n17\n0\n0\n57\n\n\nRamaphosa\n0\n0\n72\n0\n9\n546\n\n\nZuma\n0\n0\n65\n0\n1\n635\n\n\n\n\n\n\nLooking at the confusion matrix for the classification tree model against the unbalanced tf-idf data-set in Table 2 above, it was evident that the model did an poor job of predicting presidential speeches, with the majority of the predictions being assigned to two presidents (Mbeki and Zuma).\n\n\n4.2 Feed-Forward Neural Network\n\n\n\n\nTable 3: Neural Network Model Prediction Accuracies\n\n\n\n\n\n\nTokenisation model\nAccuracy\n\n\n\n\nBag of words - unbalanced\n0.396\n\n\nBag of words - under-sampled\n0.423\n\n\nBag of words - over-sampled\n0.641\n\n\nTFIDF - unbalanced\n0.403\n\n\nTFIDF - under-sampled\n0.423\n\n\nTFIDF - over-sampled\n0.630\n\n\n\n\n\n\nAs can be seen in Table 3 above, the feed-forward neural-network performed well against the over-sampled data-sets.\n\n\n\n\nTable 4: Neural Network - Confusion Matrix Against Under-Sampled Bag-of-Words Data-Set\n\n\n\nMandela\nMbeki\nRamaphosa\nZuma\n\n\n\n\nMandela\n193\n132\n81\n50\n\n\nMbeki\n113\n204\n103\n36\n\n\nRamaphosa\n62\n91\n246\n57\n\n\nZuma\n69\n95\n163\n129\n\n\n\n\n\n\nWhen looking at the confusion matrix of the model used against the under-sampled bag-of-words data-set in Table 4, it is evident that whilst the diagonal represents the highest number for each row, the model did also suffer from a reasonably high proportion of incorrect predictions.\n\n\n\n\nTable 5: Neural Network - Confusion Matrix Against Over-Sampled TF-IDF Data-Set\n\n\n\nMandela\nMbeki\nRamaphosa\nZuma\ndeKlerk\nMotlanthe\n\n\n\n\nMandela\n366\n121\n73\n99\n23\n19\n\n\nMbeki\n169\n271\n98\n114\n18\n31\n\n\nRamaphosa\n99\n66\n346\n153\n17\n20\n\n\nZuma\n105\n102\n153\n304\n16\n21\n\n\ndeKlerk\n3\n0\n0\n1\n697\n0\n\n\nMotlanthe\n8\n13\n0\n14\n1\n665\n\n\n\n\n\n\nThe confusion matrix for the over-sampled tf-idf data-set in Table 5 reveals that the model achieved very high predictive accuracy against deKlerk and Motlanthe, both of whom where heavily over-sampled because of the fact that they delivered only one SONA speech. Nonetheless, the remaining presidents also exhibit better prediction rates when compared to the previous two confusion matrices above, suggesting that the over-sampling method was effective in balancing out the data-set for predictive modelling.\n\n\n4.3 Random Forest\n\n\n\n\nTable 6: Random Forest Model Prediction Accuracies\n\n\n\n\n\n\nTokenisation model\nAccuracy\n\n\n\n\nBag of words - unbalanced\n0.343\n\n\nBag of words - under-sampled\n0.399\n\n\nBag of words - over-sampled\n0.491\n\n\nTFIDF - unbalanced\n0.335\n\n\nTFIDF - under-sampled\n0.375\n\n\nTFIDF - over-sampled\n0.473\n\n\n\n\n\n\nAs seen in Table 6, the random forest classifier produced satisfactory results across all data-sets, achieving over 49% accuracy against the over-sampled bag-of-words data-set.\n\n\n\n\nTable 7: Random Forest Model Predictions Against Oversampled TF-IDF Data-Set\n\n\n\nMandela\nMbeki\nRamaphosa\nZuma\ndeKlerk\nMotlanthe\n\n\n\n\nMandela\n39\n57\n100\n427\n42\n36\n\n\nMbeki\n9\n145\n95\n419\n20\n13\n\n\nRamaphosa\n7\n44\n245\n365\n27\n13\n\n\nZuma\n1\n37\n125\n520\n14\n4\n\n\ndeKlerk\n0\n1\n9\n68\n623\n0\n\n\nMotlanthe\n3\n11\n29\n152\n14\n492\n\n\n\n\n\n\nThe confusion matrix of the random forest classifier in Table 7, however, shows predictions skewed towards Zuma, except for the heavily over-sampled deKlerk and Motlanthe.\n\n\n4.4 Convolutional Neural Network\n\n\n\n\nTable 8: Convolutional Neural Network Model Prediction Accuracies\n\n\n\n\n\n\n\nData Set\nLoss\nAccuracy\n\n\n\n\nTop 100 words - unbalanced data set\n1.569\n0.391\n\n\nTop 100 words - under-sampled data set\n1.493\n0.379\n\n\nTop 200 words - unbalanced data set\n1.538\n0.432\n\n\nTop 200 words - under-sampled data set\n1.437\n0.447\n\n\nTop 300 words - unbalanced data set\n1.483\n0.458\n\n\nTop 300 words - under-sampled data set\n1.472\n0.453\n\n\n\n\n\n\nFinally, as shown in Table 8, the CNN classifier also produced satisfactory results across all data-sets, achieving best results of almost 46% accuracy.\n\n\n\n\nTable 9: CNN Model Predictions Against Under-Sampled TF-IDF Data-Set - Top 300 Words\n\n\n\nMandela\nMbeki\nRamaphosa\nZuma\n\n\n\n\nMandela\n260\n105\n96\n25\n\n\nMbeki\n166\n205\n100\n50\n\n\nRamaphosa\n91\n58\n304\n52\n\n\nZuma\n93\n66\n191\n136\n\n\n\n\n\n\nThe confusion matrix of the CNN classifier against the under-sampled tf-idf data-set in Table 9 shows relatively good prediction rates except for Zuma."
  },
  {
    "objectID": "assignment1.html#discussion-conclusion",
    "href": "assignment1.html#discussion-conclusion",
    "title": "Predictive Modelling of Presidential SONA Addresses in South Africa from 1994 to 2023",
    "section": "5 Discussion & Conclusion",
    "text": "5 Discussion & Conclusion\nThe assignment required building three or more predictive models that, that given a sentence of text, could predict which president was the source of that sentence. The task was performed by importing and cleaning the data, then tokenizing the data and converting it into a bag-of-words and tf-idf formats.\nGiven the imbalanced state of the data-set, the decision was made to create three different data-sets for comparison - an imbalanced, an under-sampled and an over-sampled data-set. Thereafter the three data-sets were split into training and test sets, and the models built and tuned for classification prediction.\nOf the four models, the feed-forward neural network produced the best predictive results, although with the caveat that it was against the over-sampled data-set, which produced very accurate predictions against presidents with only one SONA speech. The CNN model also produced satisfactory results, followed by the random forest, and the classification tree last.\nWhat was evident is that the imbalanced data-set and commonly-used set-of-words posed challenges to the models, perhaps suggesting the relatively low rates of accuracy. Nonetheless, when compared to random chance or a naive model (where the same president is always selected), all models were superior. Both such models, over sufficient repeated runs, would produce a best-case approximate success rate of 17% against both balanced and unbalanced data, which is inferior to even the worst performing model.\nPossible future improvements could be the investigation of other predictive models (for example Gradient Boosted Machines), and more intensive hyper-parameter tuning. In addition, the bag-of-words and tf-idf models could be enhanced to look at a larger number of words (for example 500), to evaluate performance, assuming sufficient computational resources to do so."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Assignment 1 Submission",
    "section": "",
    "text": "This website contains content related to the STA5073Z assignment 1 submission of Steven Ellis, entitled “Predictive Modelling of Presidential SONA Addresses in South Africa from 1994 to 2023”"
  }
]